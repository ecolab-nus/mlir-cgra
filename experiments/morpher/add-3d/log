// -----// IR Dump After LinalgLowerToAffineLoops (convert-linalg-to-affine-loops) //----- //
func.func @generic_0(%arg0: memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>, %arg1: memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>) {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %cst = arith.constant 1.000000e+00 : f32
  cf.br ^bb1
^bb1:  // pred: ^bb0
  %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>
  affine.for %arg2 = 0 to 1 {
    affine.for %arg3 = 0 to %0 {
      affine.for %arg4 = 0 to 384 {
        %1 = affine.load %arg0[%c0, %arg3, %arg4] : memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>
        %2 = arith.addf %1, %cst : f32
        affine.store %2, %arg1[%arg2, %arg3, %arg4] : memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>
      }
    }
  }
  return
}

insert mark for affine.for %arg4 = 0 to 384 {
  %1 = affine.load %arg0[%c0, %arg3, %arg4] : memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>
  %2 = arith.addf %1, %cst : f32
  affine.store %2, %arg1[%arg2, %arg3, %arg4] : memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>
}
// -----// IR Dump After MarkMapRegion (mark-map-region) //----- //
func.func @generic_0(%arg0: memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>, %arg1: memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>) {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %cst = arith.constant 1.000000e+00 : f32
  cf.br ^bb1
^bb1:  // pred: ^bb0
  %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>
  affine.for %arg2 = 0 to 1 {
    affine.for %arg3 = 0 to %0 {
      affine.for %arg4 = 0 to 384 {
        morpher.map_hint
        %1 = affine.load %arg0[%c0, %arg3, %arg4] : memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>
        %2 = arith.addf %1, %cst : f32
        affine.store %2, %arg1[%arg2, %arg3, %arg4] : memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>
      }
    }
  }
  return
}

// -----// IR Dump After LegalizeMorpher (legalize-morpher) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    affine.for %arg2 = 0 to 1 {
      affine.for %arg3 = 0 to %0 {
        affine.for %arg4 = 0 to 384 {
          func.call @please_map_me() : () -> ()
          %1 = affine.load %arg0[%c0, %arg3, %arg4] : memref<1x?x384xf32, #map>
          %2 = arith.addf %1, %cst : f32
          affine.store %2, %arg1[%arg2, %arg3, %arg4] : memref<1x?x384xf32, #map>
        }
      }
    }
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    %c0_0 = arith.constant 0 : index
    %c1_1 = arith.constant 1 : index
    %c1_2 = arith.constant 1 : index
    scf.for %arg2 = %c0_0 to %c1_1 step %c1_2 {
      %c0_3 = arith.constant 0 : index
      %c1_4 = arith.constant 1 : index
      scf.for %arg3 = %c0_3 to %0 step %c1_4 {
        %c0_5 = arith.constant 0 : index
        %c384 = arith.constant 384 : index
        %c1_6 = arith.constant 1 : index
        scf.for %arg4 = %c0_5 to %c384 step %c1_6 {
          func.call @please_map_me() : () -> ()
          %1 = memref.load %arg0[%c0, %arg3, %arg4] : memref<1x?x384xf32, #map>
          %2 = arith.addf %1, %cst : f32
          memref.store %2, %arg1[%arg2, %arg3, %arg4] : memref<1x?x384xf32, #map>
        }
      }
    }
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c384 = arith.constant 384 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    scf.for %arg2 = %c0 to %0 step %c1 {
      scf.for %arg3 = %c0 to %c384 step %c1 {
        func.call @please_map_me() : () -> ()
        %1 = memref.load %arg0[%c0, %arg2, %arg3] : memref<1x?x384xf32, #map>
        %2 = arith.addf %1, %cst : f32
        memref.store %2, %arg1[%c0, %arg2, %arg3] : memref<1x?x384xf32, #map>
      }
    }
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After CSE (cse) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c384 = arith.constant 384 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    scf.for %arg2 = %c0 to %0 step %c1 {
      scf.for %arg3 = %c0 to %c384 step %c1 {
        func.call @please_map_me() : () -> ()
        %1 = memref.load %arg0[%c0, %arg2, %arg3] : memref<1x?x384xf32, #map>
        %2 = arith.addf %1, %cst : f32
        memref.store %2, %arg1[%c0, %arg2, %arg3] : memref<1x?x384xf32, #map>
      }
    }
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c384 = arith.constant 384 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    cf.br ^bb1(%c0 : index)
  ^bb1(%1: index):  // 2 preds: ^bb0, ^bb5
    %2 = arith.cmpi slt, %1, %0 : index
    cf.cond_br %2, ^bb2, ^bb6
  ^bb2:  // pred: ^bb1
    cf.br ^bb3(%c0 : index)
  ^bb3(%3: index):  // 2 preds: ^bb2, ^bb4
    %4 = arith.cmpi slt, %3, %c384 : index
    cf.cond_br %4, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    call @please_map_me() : () -> ()
    %5 = memref.load %arg0[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %6 = arith.addf %5, %cst : f32
    memref.store %6, %arg1[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %7 = arith.addi %3, %c1 : index
    cf.br ^bb3(%7 : index)
  ^bb5:  // pred: ^bb3
    %8 = arith.addi %1, %c1 : index
    cf.br ^bb1(%8 : index)
  ^bb6:  // pred: ^bb1
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c384 = arith.constant 384 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    cf.br ^bb1(%c0 : index)
  ^bb1(%1: index):  // 2 preds: ^bb0, ^bb4
    %2 = arith.cmpi slt, %1, %0 : index
    cf.cond_br %2, ^bb2(%c0 : index), ^bb5
  ^bb2(%3: index):  // 2 preds: ^bb1, ^bb3
    %4 = arith.cmpi slt, %3, %c384 : index
    cf.cond_br %4, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    call @please_map_me() : () -> ()
    %5 = memref.load %arg0[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %6 = arith.addf %5, %cst : f32
    memref.store %6, %arg1[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %7 = arith.addi %3, %c1 : index
    cf.br ^bb2(%7 : index)
  ^bb4:  // pred: ^bb2
    %8 = arith.addi %1, %c1 : index
    cf.br ^bb1(%8 : index)
  ^bb5:  // pred: ^bb1
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After CSE (cse) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c384 = arith.constant 384 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    cf.br ^bb1(%c0 : index)
  ^bb1(%1: index):  // 2 preds: ^bb0, ^bb4
    %2 = arith.cmpi slt, %1, %0 : index
    cf.cond_br %2, ^bb2(%c0 : index), ^bb5
  ^bb2(%3: index):  // 2 preds: ^bb1, ^bb3
    %4 = arith.cmpi slt, %3, %c384 : index
    cf.cond_br %4, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    call @please_map_me() : () -> ()
    %5 = memref.load %arg0[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %6 = arith.addf %5, %cst : f32
    memref.store %6, %arg1[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %7 = arith.addi %3, %c1 : index
    cf.br ^bb2(%7 : index)
  ^bb4:  // pred: ^bb2
    %8 = arith.addi %1, %c1 : index
    cf.br ^bb1(%8 : index)
  ^bb5:  // pred: ^bb1
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After ConvertMathToLLVM (convert-math-to-llvm) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c384 = arith.constant 384 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    cf.br ^bb1(%c0 : index)
  ^bb1(%1: index):  // 2 preds: ^bb0, ^bb4
    %2 = arith.cmpi slt, %1, %0 : index
    cf.cond_br %2, ^bb2(%c0 : index), ^bb5
  ^bb2(%3: index):  // 2 preds: ^bb1, ^bb3
    %4 = arith.cmpi slt, %3, %c384 : index
    cf.cond_br %4, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    call @please_map_me() : () -> ()
    %5 = memref.load %arg0[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %6 = arith.addf %5, %cst : f32
    memref.store %6, %arg1[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %7 = arith.addi %3, %c1 : index
    cf.br ^bb2(%7 : index)
  ^bb4:  // pred: ^bb2
    %8 = arith.addi %1, %c1 : index
    cf.br ^bb1(%8 : index)
  ^bb5:  // pred: ^bb1
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After ConvertMathToLibm (convert-math-to-libm) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c384 = arith.constant 384 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    cf.br ^bb1(%c0 : index)
  ^bb1(%1: index):  // 2 preds: ^bb0, ^bb4
    %2 = arith.cmpi slt, %1, %0 : index
    cf.cond_br %2, ^bb2(%c0 : index), ^bb5
  ^bb2(%3: index):  // 2 preds: ^bb1, ^bb3
    %4 = arith.cmpi slt, %3, %c384 : index
    cf.cond_br %4, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    call @please_map_me() : () -> ()
    %5 = memref.load %arg0[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %6 = arith.addf %5, %cst : f32
    memref.store %6, %arg1[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %7 = arith.addi %3, %c1 : index
    cf.br ^bb2(%7 : index)
  ^bb4:  // pred: ^bb2
    %8 = arith.addi %1, %c1 : index
    cf.br ^bb1(%8 : index)
  ^bb5:  // pred: ^bb1
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After ArithmeticExpandOps (arith-expand) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %c384 = arith.constant 384 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 1.000000e+00 : f32
    %0 = memref.dim %arg0, %c1 : memref<1x?x384xf32, #map>
    cf.br ^bb1(%c0 : index)
  ^bb1(%1: index):  // 2 preds: ^bb0, ^bb4
    %2 = arith.cmpi slt, %1, %0 : index
    cf.cond_br %2, ^bb2(%c0 : index), ^bb5
  ^bb2(%3: index):  // 2 preds: ^bb1, ^bb3
    %4 = arith.cmpi slt, %3, %c384 : index
    cf.cond_br %4, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    call @please_map_me() : () -> ()
    %5 = memref.load %arg0[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %6 = arith.addf %5, %cst : f32
    memref.store %6, %arg1[%c0, %1, %3] : memref<1x?x384xf32, #map>
    %7 = arith.addi %3, %c1 : index
    cf.br ^bb2(%7 : index)
  ^bb4:  // pred: ^bb2
    %8 = arith.addi %1, %c1 : index
    cf.br ^bb1(%8 : index)
  ^bb5:  // pred: ^bb1
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After ConvertArithmeticToLLVM (convert-arith-to-llvm) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %0 = llvm.mlir.constant(384 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = builtin.unrealized_conversion_cast %1 : i64 to index
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = builtin.unrealized_conversion_cast %3 : i64 to index
    %5 = llvm.mlir.constant(1.000000e+00 : f32) : f32
    %6 = memref.dim %arg0, %2 : memref<1x?x384xf32, #map>
    %7 = builtin.unrealized_conversion_cast %6 : index to i64
    cf.br ^bb1(%4 : index)
  ^bb1(%8: index):  // 2 preds: ^bb0, ^bb4
    %9 = builtin.unrealized_conversion_cast %8 : index to i64
    %10 = llvm.icmp "slt" %9, %7 : i64
    cf.cond_br %10, ^bb2(%4 : index), ^bb5
  ^bb2(%11: index):  // 2 preds: ^bb1, ^bb3
    %12 = builtin.unrealized_conversion_cast %11 : index to i64
    %13 = llvm.icmp "slt" %12, %0 : i64
    cf.cond_br %13, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    call @please_map_me() : () -> ()
    %14 = memref.load %arg0[%4, %8, %11] : memref<1x?x384xf32, #map>
    %15 = llvm.fadd %14, %5  : f32
    memref.store %15, %arg1[%4, %8, %11] : memref<1x?x384xf32, #map>
    %16 = llvm.add %12, %1  : i64
    %17 = builtin.unrealized_conversion_cast %16 : i64 to index
    cf.br ^bb2(%17 : index)
  ^bb4:  // pred: ^bb2
    %18 = llvm.add %9, %1  : i64
    %19 = builtin.unrealized_conversion_cast %18 : i64 to index
    cf.br ^bb1(%19 : index)
  ^bb5:  // pred: ^bb1
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After ExpandOps (memref-expand) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %0 = llvm.mlir.constant(384 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = builtin.unrealized_conversion_cast %1 : i64 to index
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = builtin.unrealized_conversion_cast %3 : i64 to index
    %5 = llvm.mlir.constant(1.000000e+00 : f32) : f32
    %6 = memref.dim %arg0, %2 : memref<1x?x384xf32, #map>
    %7 = builtin.unrealized_conversion_cast %6 : index to i64
    cf.br ^bb1(%4 : index)
  ^bb1(%8: index):  // 2 preds: ^bb0, ^bb4
    %9 = builtin.unrealized_conversion_cast %8 : index to i64
    %10 = llvm.icmp "slt" %9, %7 : i64
    cf.cond_br %10, ^bb2(%4 : index), ^bb5
  ^bb2(%11: index):  // 2 preds: ^bb1, ^bb3
    %12 = builtin.unrealized_conversion_cast %11 : index to i64
    %13 = llvm.icmp "slt" %12, %0 : i64
    cf.cond_br %13, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    call @please_map_me() : () -> ()
    %14 = memref.load %arg0[%4, %8, %11] : memref<1x?x384xf32, #map>
    %15 = llvm.fadd %14, %5  : f32
    memref.store %15, %arg1[%4, %8, %11] : memref<1x?x384xf32, #map>
    %16 = llvm.add %12, %1  : i64
    %17 = builtin.unrealized_conversion_cast %16 : i64 to index
    cf.br ^bb2(%17 : index)
  ^bb4:  // pred: ^bb2
    %18 = llvm.add %9, %1  : i64
    %19 = builtin.unrealized_conversion_cast %18 : i64 to index
    cf.br ^bb1(%19 : index)
  ^bb5:  // pred: ^bb1
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After ConvertMemRefToLLVM (convert-memref-to-llvm) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<1x?x384xf32, #map> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<1x?x384xf32, #map> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>
    %2 = llvm.mlir.constant(384 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = builtin.unrealized_conversion_cast %3 : i64 to index
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = builtin.unrealized_conversion_cast %5 : i64 to index
    %7 = llvm.mlir.constant(1.000000e+00 : f32) : f32
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.extractvalue %0[3] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %10 = llvm.alloca %8 x !llvm.array<3 x i64> : (i64) -> !llvm.ptr<array<3 x i64>>
    llvm.store %9, %10 : !llvm.ptr<array<3 x i64>>
    %11 = llvm.getelementptr %10[0, %3] : (!llvm.ptr<array<3 x i64>>, i64) -> !llvm.ptr<i64>
    %12 = llvm.load %11 : !llvm.ptr<i64>
    %13 = builtin.unrealized_conversion_cast %12 : i64 to index
    %14 = builtin.unrealized_conversion_cast %13 : index to i64
    cf.br ^bb1(%6 : index)
  ^bb1(%15: index):  // 2 preds: ^bb0, ^bb4
    %16 = builtin.unrealized_conversion_cast %15 : index to i64
    %17 = builtin.unrealized_conversion_cast %15 : index to i64
    %18 = llvm.icmp "slt" %17, %14 : i64
    cf.cond_br %18, ^bb2(%6 : index), ^bb5
  ^bb2(%19: index):  // 2 preds: ^bb1, ^bb3
    %20 = builtin.unrealized_conversion_cast %19 : index to i64
    %21 = builtin.unrealized_conversion_cast %19 : index to i64
    %22 = llvm.icmp "slt" %21, %2 : i64
    cf.cond_br %22, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    call @please_map_me() : () -> ()
    %23 = llvm.extractvalue %0[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %24 = llvm.extractvalue %0[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %25 = llvm.mlir.constant(4608 : index) : i64
    %26 = llvm.mul %5, %25  : i64
    %27 = llvm.add %24, %26  : i64
    %28 = llvm.mlir.constant(384 : index) : i64
    %29 = llvm.mul %16, %28  : i64
    %30 = llvm.add %27, %29  : i64
    %31 = llvm.add %30, %20  : i64
    %32 = llvm.getelementptr %23[%31] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %33 = llvm.load %32 : !llvm.ptr<f32>
    %34 = llvm.fadd %33, %7  : f32
    %35 = llvm.extractvalue %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %36 = llvm.extractvalue %1[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %37 = llvm.mlir.constant(4608 : index) : i64
    %38 = llvm.mul %5, %37  : i64
    %39 = llvm.add %36, %38  : i64
    %40 = llvm.mlir.constant(384 : index) : i64
    %41 = llvm.mul %16, %40  : i64
    %42 = llvm.add %39, %41  : i64
    %43 = llvm.add %42, %20  : i64
    %44 = llvm.getelementptr %35[%43] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    llvm.store %34, %44 : !llvm.ptr<f32>
    %45 = llvm.add %21, %3  : i64
    %46 = builtin.unrealized_conversion_cast %45 : i64 to index
    cf.br ^bb2(%46 : index)
  ^bb4:  // pred: ^bb2
    %47 = llvm.add %17, %3  : i64
    %48 = builtin.unrealized_conversion_cast %47 : i64 to index
    cf.br ^bb1(%48 : index)
  ^bb5:  // pred: ^bb1
    return
  }
  func.func private @please_map_me()
}


// -----// IR Dump After ConvertFuncToLLVM (convert-func-to-llvm) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module attributes {llvm.data_layout = ""} {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<1x?x384xf32, #map> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<1x?x384xf32, #map> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>
    %2 = llvm.mlir.constant(384 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = builtin.unrealized_conversion_cast %3 : i64 to index
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = builtin.unrealized_conversion_cast %5 : i64 to index
    %7 = llvm.mlir.constant(1.000000e+00 : f32) : f32
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.extractvalue %0[3] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %10 = llvm.alloca %8 x !llvm.array<3 x i64> : (i64) -> !llvm.ptr<array<3 x i64>>
    llvm.store %9, %10 : !llvm.ptr<array<3 x i64>>
    %11 = llvm.getelementptr %10[0, %3] : (!llvm.ptr<array<3 x i64>>, i64) -> !llvm.ptr<i64>
    %12 = llvm.load %11 : !llvm.ptr<i64>
    %13 = builtin.unrealized_conversion_cast %12 : i64 to index
    %14 = builtin.unrealized_conversion_cast %13 : index to i64
    cf.br ^bb1(%6 : index)
  ^bb1(%15: index):  // 2 preds: ^bb0, ^bb4
    %16 = builtin.unrealized_conversion_cast %15 : index to i64
    %17 = builtin.unrealized_conversion_cast %15 : index to i64
    %18 = llvm.icmp "slt" %17, %14 : i64
    cf.cond_br %18, ^bb2(%6 : index), ^bb5
  ^bb2(%19: index):  // 2 preds: ^bb1, ^bb3
    %20 = builtin.unrealized_conversion_cast %19 : index to i64
    %21 = builtin.unrealized_conversion_cast %19 : index to i64
    %22 = llvm.icmp "slt" %21, %2 : i64
    llvm.cond_br %22, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    llvm.call @please_map_me() : () -> ()
    %23 = llvm.extractvalue %0[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %24 = llvm.extractvalue %0[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %25 = llvm.mlir.constant(4608 : index) : i64
    %26 = llvm.mul %5, %25  : i64
    %27 = llvm.add %24, %26  : i64
    %28 = llvm.mlir.constant(384 : index) : i64
    %29 = llvm.mul %16, %28  : i64
    %30 = llvm.add %27, %29  : i64
    %31 = llvm.add %30, %20  : i64
    %32 = llvm.getelementptr %23[%31] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %33 = llvm.load %32 : !llvm.ptr<f32>
    %34 = llvm.fadd %33, %7  : f32
    %35 = llvm.extractvalue %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %36 = llvm.extractvalue %1[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %37 = llvm.mlir.constant(4608 : index) : i64
    %38 = llvm.mul %5, %37  : i64
    %39 = llvm.add %36, %38  : i64
    %40 = llvm.mlir.constant(384 : index) : i64
    %41 = llvm.mul %16, %40  : i64
    %42 = llvm.add %39, %41  : i64
    %43 = llvm.add %42, %20  : i64
    %44 = llvm.getelementptr %35[%43] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    llvm.store %34, %44 : !llvm.ptr<f32>
    %45 = llvm.add %21, %3  : i64
    %46 = builtin.unrealized_conversion_cast %45 : i64 to index
    cf.br ^bb2(%46 : index)
  ^bb4:  // pred: ^bb2
    %47 = llvm.add %17, %3  : i64
    %48 = builtin.unrealized_conversion_cast %47 : i64 to index
    cf.br ^bb1(%48 : index)
  ^bb5:  // pred: ^bb1
    llvm.return
  }
  llvm.func @please_map_me() attributes {sym_visibility = "private"}
}


// -----// IR Dump After ConvertControlFlowToLLVM (convert-cf-to-llvm) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module attributes {llvm.data_layout = ""} {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<1x?x384xf32, #map> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<1x?x384xf32, #map> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>
    %2 = llvm.mlir.constant(384 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = builtin.unrealized_conversion_cast %3 : i64 to index
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = builtin.unrealized_conversion_cast %5 : i64 to index
    %7 = llvm.mlir.constant(1.000000e+00 : f32) : f32
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.extractvalue %0[3] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %10 = llvm.alloca %8 x !llvm.array<3 x i64> : (i64) -> !llvm.ptr<array<3 x i64>>
    llvm.store %9, %10 : !llvm.ptr<array<3 x i64>>
    %11 = llvm.getelementptr %10[0, %3] : (!llvm.ptr<array<3 x i64>>, i64) -> !llvm.ptr<i64>
    %12 = llvm.load %11 : !llvm.ptr<i64>
    %13 = builtin.unrealized_conversion_cast %12 : i64 to index
    %14 = builtin.unrealized_conversion_cast %13 : index to i64
    cf.br ^bb1(%6 : index)
  ^bb1(%15: index):  // 2 preds: ^bb0, ^bb4
    %16 = builtin.unrealized_conversion_cast %15 : index to i64
    %17 = builtin.unrealized_conversion_cast %15 : index to i64
    %18 = llvm.icmp "slt" %17, %14 : i64
    cf.cond_br %18, ^bb2(%6 : index), ^bb5
  ^bb2(%19: index):  // 2 preds: ^bb1, ^bb3
    %20 = builtin.unrealized_conversion_cast %19 : index to i64
    %21 = builtin.unrealized_conversion_cast %19 : index to i64
    %22 = llvm.icmp "slt" %21, %2 : i64
    llvm.cond_br %22, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    llvm.call @please_map_me() : () -> ()
    %23 = llvm.extractvalue %0[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %24 = llvm.extractvalue %0[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %25 = llvm.mlir.constant(4608 : index) : i64
    %26 = llvm.mul %5, %25  : i64
    %27 = llvm.add %24, %26  : i64
    %28 = llvm.mlir.constant(384 : index) : i64
    %29 = llvm.mul %16, %28  : i64
    %30 = llvm.add %27, %29  : i64
    %31 = llvm.add %30, %20  : i64
    %32 = llvm.getelementptr %23[%31] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %33 = llvm.load %32 : !llvm.ptr<f32>
    %34 = llvm.fadd %33, %7  : f32
    %35 = llvm.extractvalue %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %36 = llvm.extractvalue %1[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %37 = llvm.mlir.constant(4608 : index) : i64
    %38 = llvm.mul %5, %37  : i64
    %39 = llvm.add %36, %38  : i64
    %40 = llvm.mlir.constant(384 : index) : i64
    %41 = llvm.mul %16, %40  : i64
    %42 = llvm.add %39, %41  : i64
    %43 = llvm.add %42, %20  : i64
    %44 = llvm.getelementptr %35[%43] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    llvm.store %34, %44 : !llvm.ptr<f32>
    %45 = llvm.add %21, %3  : i64
    %46 = builtin.unrealized_conversion_cast %45 : i64 to index
    cf.br ^bb2(%46 : index)
  ^bb4:  // pred: ^bb2
    %47 = llvm.add %17, %3  : i64
    %48 = builtin.unrealized_conversion_cast %47 : i64 to index
    cf.br ^bb1(%48 : index)
  ^bb5:  // pred: ^bb1
    llvm.return
  }
  llvm.func @please_map_me() attributes {sym_visibility = "private"}
}


01-linalg.mlir:8:3: error: failed to legalize operation 'builtin.unrealized_conversion_cast' that was explicitly marked illegal
  linalg.generic {indexing_maps = [#map1, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%arg0 : memref<1x?x384xf32, #map0>) outs(%arg1 : memref<1x?x384xf32, #map0>) attrs =  {__internal_linalg_transform__ = "offloadedOnCGRA"} {
  ^
01-linalg.mlir:8:3: note: see current operation: %0 = "builtin.unrealized_conversion_cast"(%arg0) : (memref<1x?x384xf32, affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>>) -> !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>
// -----// IR Dump After ReconcileUnrealizedCasts Failed (reconcile-unrealized-casts) //----- //
#map = affine_map<(d0, d1, d2)[s0] -> (d0 * 4608 + s0 + d1 * 384 + d2)>
module attributes {llvm.data_layout = ""} {
  func.func @generic_0(%arg0: memref<1x?x384xf32, #map>, %arg1: memref<1x?x384xf32, #map>) {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<1x?x384xf32, #map> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<1x?x384xf32, #map> to !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>
    %2 = llvm.mlir.constant(384 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = builtin.unrealized_conversion_cast %3 : i64 to index
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = builtin.unrealized_conversion_cast %5 : i64 to index
    %7 = llvm.mlir.constant(1.000000e+00 : f32) : f32
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.extractvalue %0[3] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %10 = llvm.alloca %8 x !llvm.array<3 x i64> : (i64) -> !llvm.ptr<array<3 x i64>>
    llvm.store %9, %10 : !llvm.ptr<array<3 x i64>>
    %11 = llvm.getelementptr %10[0, %3] : (!llvm.ptr<array<3 x i64>>, i64) -> !llvm.ptr<i64>
    %12 = llvm.load %11 : !llvm.ptr<i64>
    %13 = builtin.unrealized_conversion_cast %12 : i64 to index
    %14 = builtin.unrealized_conversion_cast %13 : index to i64
    cf.br ^bb1(%6 : index)
  ^bb1(%15: index):  // 2 preds: ^bb0, ^bb4
    %16 = builtin.unrealized_conversion_cast %15 : index to i64
    %17 = builtin.unrealized_conversion_cast %15 : index to i64
    %18 = llvm.icmp "slt" %17, %14 : i64
    cf.cond_br %18, ^bb2(%6 : index), ^bb5
  ^bb2(%19: index):  // 2 preds: ^bb1, ^bb3
    %20 = builtin.unrealized_conversion_cast %19 : index to i64
    %21 = builtin.unrealized_conversion_cast %19 : index to i64
    %22 = llvm.icmp "slt" %21, %2 : i64
    llvm.cond_br %22, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    llvm.call @please_map_me() : () -> ()
    %23 = llvm.extractvalue %0[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %24 = llvm.extractvalue %0[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %25 = llvm.mlir.constant(4608 : index) : i64
    %26 = llvm.mul %5, %25  : i64
    %27 = llvm.add %24, %26  : i64
    %28 = llvm.mlir.constant(384 : index) : i64
    %29 = llvm.mul %16, %28  : i64
    %30 = llvm.add %27, %29  : i64
    %31 = llvm.add %30, %20  : i64
    %32 = llvm.getelementptr %23[%31] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %33 = llvm.load %32 : !llvm.ptr<f32>
    %34 = llvm.fadd %33, %7  : f32
    %35 = llvm.extractvalue %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %36 = llvm.extractvalue %1[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %37 = llvm.mlir.constant(4608 : index) : i64
    %38 = llvm.mul %5, %37  : i64
    %39 = llvm.add %36, %38  : i64
    %40 = llvm.mlir.constant(384 : index) : i64
    %41 = llvm.mul %16, %40  : i64
    %42 = llvm.add %39, %41  : i64
    %43 = llvm.add %42, %20  : i64
    %44 = llvm.getelementptr %35[%43] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    llvm.store %34, %44 : !llvm.ptr<f32>
    %45 = llvm.add %21, %3  : i64
    %46 = builtin.unrealized_conversion_cast %45 : i64 to index
    cf.br ^bb2(%46 : index)
  ^bb4:  // pred: ^bb2
    %47 = llvm.add %17, %3  : i64
    %48 = builtin.unrealized_conversion_cast %47 : i64 to index
    cf.br ^bb1(%48 : index)
  ^bb5:  // pred: ^bb1
    llvm.return
  }
  llvm.func @please_map_me() attributes {sym_visibility = "private"}
}


